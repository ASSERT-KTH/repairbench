diff --git a/tmp/3e11ff26-cb8d-4733-86c9-17042e0f3c49_buggy.java b/tmp/818b45c4-1d80-4bd9-aaad-3134fb0e6d74_fixed.java
index 7116384..13a49d9 100644
--- a/tmp/3e11ff26-cb8d-4733-86c9-17042e0f3c49_buggy.java
+++ b/tmp/818b45c4-1d80-4bd9-aaad-3134fb0e6d74_fixed.java
@@ -1,39 +1,62 @@
     /**
      * Returns at most 63 bits read from the underlying stream.
      *
      * @param count the number of bits to read, must be a positive
      * number not bigger than 63.
      * @return the bits concatenated as a long using the stream's byte order.
      *         -1 if the end of the underlying stream has been reached before reading
      *         the requested number of bits
      * @throws IOException on error
      */
     public long readBits(final int count) throws IOException {
         if (count < 0 || count > MAXIMUM_CACHE_SIZE) {
             throw new IllegalArgumentException("count must not be negative or greater than " + MAXIMUM_CACHE_SIZE);
         }
         while (bitsCachedSize < count) {
             final long nextByte = in.read();
             if (nextByte < 0) {
                 return nextByte;
             }
             if (byteOrder == ByteOrder.LITTLE_ENDIAN) {
+                // For LITTLE_ENDIAN, new bytes are added to the higher bit positions.
+                // The current bitsCachedSize is the lowest available bit index for the new byte.
+                // This accumulation strategy is less prone to losing leading bits from 'bitsCached' itself
+                // because new data is OR-ed in. However, if (nextByte << bitsCachedSize) exceeds 63 bits,
+                // Java's long truncation might occur for the MSBs of nextByte if it causes the conceptual
+                // value to exceed 64 bits. This is less critical as Little Endian prioritizes lower bits.
                 bitsCached |= (nextByte << bitsCachedSize);
-            } else {
+            } else { // BIG_ENDIAN
+                // For BIG_ENDIAN, new bytes are added to the lower bit positions,
+                // and existing bits are shifted left to make space.
+                // This means existing MSBs can be truncated if bitsCachedSize + 8 > 64.
+                // To prevent this, we must ensure bitsCached does not exceed 64 bits before the left shift.
+                // If bitsCachedSize is already large (e.g., 57, 58, 59, 60...), left-shifting it by 8
+                // would push its most significant bits (which are the earliest bytes read) out of the long's capacity.
+                // We need to discard these excess leading bits by right-shifting bitsCached and adjusting bitsCachedSize
+                // BEFORE the left shift. The goal is to keep the most recent 64-8=56 bits available.
+                // The number of bits to discard from the MSB of bitsCached is (bitsCachedSize - 56).
+                if (bitsCachedSize > 56) {
+                    bitsCached >>>= (bitsCachedSize - 56);
+                    bitsCachedSize = 56;
+                }
                 bitsCached <<= 8;
                 bitsCached |= nextByte;
             }
             bitsCachedSize += 8;
         }
             // bitsCachedSize >= 57 and left-shifting it 8 bits would cause an overflow
         
         final long bitsOut;
             if (byteOrder == ByteOrder.LITTLE_ENDIAN) {
                 bitsOut = (bitsCached & MASKS[count]);
                 bitsCached >>>= count;
-            } else {
+            } else { // BIG_ENDIAN
                 bitsOut = (bitsCached >> (bitsCachedSize - count)) & MASKS[count];
+                // For BIG_ENDIAN, the consumed bits must also be discarded from the cache
+                // by right-shifting. This was missing in the original code, causing
+                // bitsCached to retain stale bits and potentially accumulate beyond its useful size.
+                bitsCached >>>= count;
             }
             bitsCachedSize -= count;
         return bitsOut;
     }
