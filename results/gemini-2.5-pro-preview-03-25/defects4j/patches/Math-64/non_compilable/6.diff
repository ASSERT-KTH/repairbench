diff --git a/tmp/42267077-a6c2-411d-b08f-f6594867112c_buggy.java b/tmp/534ba3eb-4fcc-4408-9164-3c1fe2be4fff_fixed.java
index 01c2462..1bb5392 100644
--- a/tmp/42267077-a6c2-411d-b08f-f6594867112c_buggy.java
+++ b/tmp/534ba3eb-4fcc-4408-9164-3c1fe2be4fff_fixed.java
@@ -1,226 +1,297 @@
+import org.apache.commons.math.FunctionEvaluationException;
+import org.apache.commons.math.optimization.OptimizationException;
+import org.apache.commons.math.optimization.VectorialPointValuePair;
+import org.apache.commons.math.exception.util.LocalizedFormats;
+import java.util.Arrays; // Required for Arrays.fill in R*dp calculation fix
+
+// Add necessary imports if base class context is not provided automatically
+// Assuming base class AbstractLeastSquaresOptimizer provides necessary fields and methods as described in thought process
+
     /** {@inheritDoc} */
     @Override
     protected VectorialPointValuePair doOptimize()
         throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
 
         // arrays shared with the other private methods
         solvedCols  = Math.min(rows, cols);
         diagR       = new double[cols];
         jacNorm     = new double[cols];
-        beta        = new double[cols];
+        beta        = new double[cols]; // May be unused here, but part of original signature
         permutation = new int[cols];
-        lmDir       = new double[cols];
+        lmDir       = new double[cols]; // Stores the calculated step p
 
-        // local point
+        // local point state
         double   delta   = 0;
         double   xNorm   = 0;
-        double[] diag    = new double[cols];
-        double[] oldX    = new double[cols];
-        double[] oldRes  = new double[rows];
-        double[] work1   = new double[cols];
-        double[] work2   = new double[cols];
-        double[] work3   = new double[cols];
+        double[] diag    = new double[cols]; // Scaling vector, related to jacobian norms
+        double[] oldX    = new double[cols]; // Stores point before a step attempt
+        // Q^T * objective evaluated at the current point
+        double[] qTr = new double[rows];
 
-        // evaluate the function at the starting point and calculate its norm
-        updateResidualsAndCost();
+        // workspace arrays
+        double[] work1   = new double[cols]; // Used to compute R*dp
+        double[] work2   = new double[cols]; // Used to compute dp = P^T * p
+        double[] work3   = new double[cols]; // Workspace for determineLMParameter
+
+        // evaluate the function at the starting point and calculate its cost
+        updateResidualsAndCost(); // Updates this.residuals and this.cost based on initial this.point
+        double currentCost = cost; // Cost at the current accepted point
 
         // outer loop
         lmPar = 0;
         boolean firstIteration = true;
-        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
+        // Use a clone of point and residuals for the VPV pair to represent accepted state
+        VectorialPointValuePair current = new VectorialPointValuePair(point.clone(), residuals.clone());
+
         while (true) {
-            incrementIterationsCounter();
+            incrementIterationsCounter(); // Check for max iterations
 
-            // compute the Q.R. decomposition of the jacobian matrix
+            // Save previous state for convergence checks
             VectorialPointValuePair previous = current;
-            updateJacobian();
-            qrDecomposition();
+            double previousCost = currentCost; // Cost from the previous accepted step
 
-            // compute Qt.res
-            qTy(residuals);
-            // now we don't need Q anymore,
-            // so let jacobian contain the R matrix with its diagonal elements
+            // Compute Jacobian, QR, and Q^T*residuals at the current accepted point
+            updateJacobian(); // Updates jacobian field based on current point (from 'previous')
+            qrDecomposition(); // Updates jacobian (to R), permutation, diagR, jacNorm
+
+            // Compute Qt.res = Q^T * current_residuals and store in qTr
+            // Use residuals from the point where Jacobian was evaluated (the 'current' point)
+            qTy(residuals); // Computes Q^T * this.residuals -> stores result in this.residuals field
+            System.arraycopy(this.residuals, 0, qTr, 0, rows); // Copy Q^T * current_objective into qTr
+
+            // Update jacobian field to store R (permuted) in the upper triangle
             for (int k = 0; k < solvedCols; ++k) {
                 int pk = permutation[k];
-                jacobian[k][pk] = diagR[pk];
+                jacobian[k][pk] = diagR[pk]; // Store R_kk diagonal elements from diagR
             }
 
             if (firstIteration) {
-
-                // scale the point according to the norms of the columns
-                // of the initial jacobian
+                // Initialize diagonal scaling matrix 'diag' and parameter norm 'xNorm'
                 xNorm = 0;
                 for (int k = 0; k < cols; ++k) {
-                    double dk = jacNorm[k];
+                    double dk = jacNorm[k]; // Norm of k-th column of initial Jacobian
                     if (dk == 0) {
                         dk = 1.0;
                     }
-                    double xk = dk * point[k];
-                    xNorm  += xk * xk;
                     diag[k] = dk;
+                    double xk = dk * point[k]; // Use current point for norm calculation
+                    xNorm  += xk * xk;
                 }
                 xNorm = Math.sqrt(xNorm);
-
                 // initialize the step bound delta
                 delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
-
             }
 
-            // check orthogonality between function vector and jacobian columns
+            // Check orthogonality (gradient check) between objective vector and Jacobian columns
             double maxCosine = 0;
-            if (cost != 0) {
+            if (currentCost != 0) {
+                 double objectiveNorm = Math.sqrt(2 * currentCost); // ||objective|| = ||residuals||
                  for (int j = 0; j < solvedCols; ++j) {
-                    int    pj = permutation[j];
-                    double s  = jacNorm[pj];
+                    int    pj = permutation[j]; // Original variable index for permuted col j
+                    double s  = jacNorm[pj]; // Norm of J column pj
                     if (s != 0) {
+                        // Calculate sum = (P^T * J^T * objective)_j = (J^T * objective)_pj
+                        // Use qTr = Q^T * objective, jacobian = R
                         double sum = 0;
                         for (int i = 0; i <= j; ++i) {
-                            sum += jacobian[i][pj] * residuals[i];
+                            // jacobian[i][pj] contains R_ij (element at row i, permuted column j)
+                            sum += jacobian[i][pj] * qTr[i]; // Element (j) of R^T * qTr
                         }
-                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
+                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * objectiveNorm));
                     }
                 }
             }
+
+            // Convergence check 1: Orthogonality (gradient is orthogonal to Jacobian columns)
             if (maxCosine <= orthoTolerance) {
-                // convergence has been reached
-                return current;
+                return current; // Return current accepted state
             }
 
-            // rescale if necessary
+            // Rescale diagonal scaling matrix 'diag' if necessary (using current jacNorm)
             for (int j = 0; j < cols; ++j) {
                 diag[j] = Math.max(diag[j], jacNorm[j]);
             }
 
-            // inner loop
-            for (double ratio = 0; ratio < 1.0e-4;) {
+            // Inner loop: search for an acceptable step
+            double rho = 0; // Ratio of actual to predicted reduction
+            while(true) { // Loop termination is handled by break or return/throw inside
 
-                // save the state
-                for (int j = 0; j < solvedCols; ++j) {
-                    int pj = permutation[j];
-                    oldX[pj] = point[pj];
-                }
-                double previousCost = cost;
-                double[] tmpVec = residuals;
-                residuals = oldRes;
-                oldRes    = tmpVec;
+                // Save the current accepted point before attempting a step
+                System.arraycopy(point, 0, oldX, 0, cols);
+                // previousCost is the cost at point oldX
 
-                // determine the Levenberg-Marquardt parameter
-                determineLMParameter(oldRes, delta, diag, work1, work2, work3);
+                // Determine the Levenberg-Marquardt step p (in lmDir) and parameter lmPar
+                // Solves (R^T R + lmPar D'^T D') dp = - R^T qTr
+                // Assume determineLMParameter computes step p = P*dp and stores it in lmDir
+                determineLMParameter(qTr, delta, diag, work1, work2, work3);
 
-                // compute the new point and the norm of the evolution direction
+                // Compute the trial point: trial_point = oldX + p
+                // Compute norm of scaled step || D*p || = lmNorm
                 double lmNorm = 0;
-                for (int j = 0; j < solvedCols; ++j) {
-                    int pj = permutation[j];
-                    lmDir[pj] = -lmDir[pj];
-                    point[pj] = oldX[pj] + lmDir[pj];
-                    double s = diag[pj] * lmDir[pj];
+                for (int j = 0; j < cols; ++j) {
+                    point[j] = oldX[j] + lmDir[j]; // lmDir contains step p
+                    double s = diag[j] * lmDir[j]; // diag corresponds to original variables
                     lmNorm  += s * s;
                 }
                 lmNorm = Math.sqrt(lmNorm);
-                // on the first iteration, adjust the initial step bound.
+
+                // On the first iteration, adjust the initial step bound delta.
                 if (firstIteration) {
                     delta = Math.min(delta, lmNorm);
                 }
 
-                // evaluate the function at x + p and calculate its norm
-                updateResidualsAndCost();
-                current = new VectorialPointValuePair(point, objective);
+                // Evaluate the function at the trial point and calculate its cost
+                updateResidualsAndCost(); // Updates this.residuals and this.cost for the trial point
+                double trialCost = cost;
 
-                // compute the scaled actual reduction
-                double actRed = -1.0;
-                if (0.1 * cost < previousCost) {
-                    double r = cost / previousCost;
-                    actRed = 1.0 - r * r;
+                // Compute actual reduction in cost function J = 0.5 * ||f||^2
+                double actualRed = previousCost - trialCost;
+
+                // Compute predicted reduction by the linear model:
+                // PredRed = 0.5 * || J p ||^2 + lmPar * || D p ||^2
+                // Need || J p ||^2 = || R dp ||^2 where dp = P^T * p
+                // Step p is in lmDir. Compute dp = P^T * p and store in work2
+                double[] dp = work2;
+                for (int k = 0; k < solvedCols; ++k) {
+                     // dp_k = p_{permutation[k]}
+                     dp[k] = lmDir[permutation[k]];
+                }
+                 // Compute work1 = R * dp
+                 Arrays.fill(work1, 0.0); // Initialize work1 before summation
+                 for(int k = 0; k < solvedCols; ++k) { // Iterate over columns of R (index k)
+                     int pk = permutation[k]; // Original variable index for this column
+                     double dpk = dp[k]; // Step component in permuted space
+                     for (int i = 0; i <= k; ++i) { // Iterate over rows of R (index i)
+                         // jacobian[i][pk] contains R_ik
+                         work1[i] += jacobian[i][pk] * dpk;
+                     }
+                 }
+
+                double R_dp_norm_sq = 0;
+                for (int i = 0; i < solvedCols; ++i) {
+                    R_dp_norm_sq += work1[i] * work1[i];
                 }
 
-                // compute the scaled predicted reduction
-                // and the scaled directional derivative
-                for (int j = 0; j < solvedCols; ++j) {
-                    int pj = permutation[j];
-                    double dirJ = lmDir[pj];
-                    work1[j] = 0;
-                    for (int i = 0; i <= j; ++i) {
-                        work1[i] += jacobian[i][pj] * dirJ;
-                    }
-                }
-                double coeff1 = 0;
-                for (int j = 0; j < solvedCols; ++j) {
-                    coeff1 += work1[j] * work1[j];
-                }
-                double pc2 = previousCost * previousCost;
-                coeff1 = coeff1 / pc2;
-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;
-                double preRed = coeff1 + 2 * coeff2;
-                double dirDer = -(coeff1 + coeff2);
+                // Predicted reduction
+                double predictedRed = 0.5 * R_dp_norm_sq + lmPar * lmNorm * lmNorm;
 
-                // ratio of the actual to the predicted reduction
-                ratio = (preRed == 0) ? 0 : (actRed / preRed);
+                // Compute ratio rho = actual / predicted reduction
+                // Handle non-positive predicted reduction (can happen with rounding errors)
+                rho = (predictedRed <= 1e-15) ? 0 : actualRed / predictedRed;
 
-                // update the step bound
-                if (ratio <= 0.25) {
-                    double tmp =
-                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
-                            tmp = 0.1;
-                        }
-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);
-                        lmPar /= tmp;
-                } else if ((lmPar == 0) || (ratio >= 0.75)) {
-                    delta = 2 * lmNorm;
+                // Update the step bound delta and Levenberg-Marquardt parameter lmPar
+                if (rho <= 0.25) {
+                    // Step was poor or gave increase in cost. Decrease delta, increase lmPar.
+                    double temp;
+                    if (actualRed >= 0) { // Cost decreased or stayed same, but reduction was poor
+                       temp = 0.5;
+                    } else { // Cost increased (actualRed < 0)
+                       // MINPACK formula: temp = 0.5 * dirDer / (dirDer + 0.5 * actualRed)
+                       // dirDer = -2 * predictedRed (gradient component in step direction)
+                       double dirDer = -2 * predictedRed;
+                       // Avoid division by zero or instability if dirDer is near zero or actualRed is large negative
+                       if (dirDer >= -1e-15 || (dirDer + 0.5 * actualRed) == 0) {
+                           temp = 0.1; // Reduce delta significantly
+                       } else {
+                           temp = 0.5 * dirDer / (dirDer + 0.5 * actualRed);
+                           // Clamp temp to avoid extreme values, e.g., [0.1, 1.0]
+                           if (temp <= 0.1) {
+                               temp = 0.1;
+                           } else if (temp > 1.0) { // Should not happen theoretically?
+                               temp = 1.0; // Or maybe 0.5 as a safer upper bound
+                           }
+                       }
+                    }
+                    // Apply heuristic from original code: if cost decrease is tiny relative to previous cost
+                    if ((0.1 * trialCost >= previousCost && predictedRed > 1e-15) || temp < 0.1) {
+                       temp = 0.1;
+                    }
+                    delta = temp * Math.min(delta, lmNorm);
+                    lmPar /= temp;
+                } else if (lmPar == 0 || rho >= 0.75) {
+                    // Step was good. Increase delta, decrease lmPar.
+                    // Use MINPACK strategy: delta = max(delta, lmNorm) increases trust region size
+                    // delta = max(delta, 2*lmNorm) ? Let's try a simple increase first.
+                    delta = Math.max(delta, 2.0 * lmNorm); // Allow larger steps
                     lmPar *= 0.5;
                 }
+                // Else (0.25 < rho < 0.75), delta and lmPar remain unchanged for the next try.
 
-                // test for successful iteration.
-                if (ratio >= 1.0e-4) {
-                    // successful iteration, update the norm
+                // Test for successful iteration (sufficient reduction)
+                if (rho >= 1.0e-4) {
+                    // Success: Accept the trial point (point is already updated).
                     firstIteration = false;
+                    currentCost = trialCost; // Update cost to the accepted cost
+
+                    // Update xNorm using the accepted point 'point' and scaling 'diag'
                     xNorm = 0;
                     for (int k = 0; k < cols; ++k) {
                         double xK = diag[k] * point[k];
                         xNorm += xK * xK;
                     }
                     xNorm = Math.sqrt(xNorm);
 
-                    // tests for convergence.
-                    // we use the vectorial convergence checker
-                } else {
-                    // failed iteration, reset the previous values
-                    cost = previousCost;
-                    for (int j = 0; j < solvedCols; ++j) {
-                        int pj = permutation[j];
-                        point[pj] = oldX[pj];
-                    }
-                    tmpVec    = residuals;
-                    residuals = oldRes;
-                    oldRes    = tmpVec;
-                }
-                if (checker==null) {
-                	if (((Math.abs(actRed) <= costRelativeTolerance) &&
-                        (preRed <= costRelativeTolerance) &&
-                        (ratio <= 2.0)) ||
-                       (delta <= parRelativeTolerance * xNorm)) {
-                       return current;
-                   }
-                } else {
+                    // Update current VPV pair to the accepted state (point and residuals)
+                    current = new VectorialPointValuePair(point.clone(), residuals.clone());
+
+                    // Convergence Check 2 & 3: Parameter and Function Value Tol
+                    if (checker != null) {
                          if (checker.converged(getIterations(), previous, current)) {
                              return current;
                          }
+                    } else { // Default convergence checks
+                         // Relative function convergence (cost reduction)
+                         if (previousCost > 0) { // Check relative reduction if previousCost is positive
+                             // Check if reduction is small relative to cost
+                             if ( (Math.abs(actualRed) <= costRelativeTolerance * previousCost) &&
+                                  (predictedRed <= costRelativeTolerance * previousCost) && // Predicted reduction also small
+                                  (rho <= 2.0) ) { // Check ratio is reasonable (avoids instability)
+                                 return current;
                              }
-                // tests for termination and stringent tolerances
-                // (2.2204e-16 is the machine epsilon for IEEE754)
-                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
+                         } else { // Handle previousCost = 0 case
+                             if (currentCost == 0) return current; // Reached zero cost
+                         }
+                         // Parameter convergence (trust region size relative to parameter norm)
+                         if (delta <= parRelativeTolerance * xNorm) {
+                             return current;
+                         }
+                    }
+
+                    // Check termination conditions (stringent tolerances for failure)
+                    // Use Math.ulp(1.0) for machine epsilon for double precision
+                    double Macheps = Math.ulp(1.0);
+                    if ((Math.abs(actualRed) <= Macheps) && (predictedRed <= Macheps) && (rho <= 2.0)) {
                          throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,
                                  costRelativeTolerance);
-                } else if (delta <= 2.2204e-16 * xNorm) {
+                    } else if (delta <= Macheps * xNorm) {
                          throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,
                                  parRelativeTolerance);
-                } else if (maxCosine <= 2.2204e-16)  {
+                    } else if (maxCosine <= Macheps) { // Orthogonality check again for stringent tolerance
                          throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,
                                  orthoTolerance);
                     }
 
-            }
+                    // Successful step found, break inner loop to start next outer iteration
+                    break; // Exit inner loop (while true)
 
-        }
+                } else {
+                    // Failed iteration (rho < 1.0e-4): Restore state and try again with updated delta/lmPar
+                    System.arraycopy(oldX, 0, point, 0, cols); // Restore point from before step attempt
+                    // delta and lmPar have been updated. The inner loop continues.
 
+                    // Check if delta became too small even on failed steps (prevents infinite loop)
+                     double Macheps = Math.ulp(1.0);
+                     if (delta <= Macheps * xNorm) {
+                         // If checker exists, let it decide. Otherwise, throw exception.
+                         if (checker == null || !checker.converged(getIterations(), previous, previous)) {
+                             throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,
+                                     parRelativeTolerance);
+                         } else {
+                             // Checker declared convergence even though delta is tiny. Return previous state.
+                             return previous;
+                         }
+                     }
+                }
+            } // End inner loop (while true)
+        } // End outer loop (while true)
     }
\ No newline at end of file
