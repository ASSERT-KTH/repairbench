diff --git a/tmp/d974e9b6-86a8-4034-8e1e-2e003797a770_buggy.java b/tmp/a0fe6d43-6a57-4d78-9903-526f482ca461_fixed.java
index 01c2462..2a8c2a1 100644
--- a/tmp/d974e9b6-86a8-4034-8e1e-2e003797a770_buggy.java
+++ b/tmp/a0fe6d43-6a57-4d78-9903-526f482ca461_fixed.java
@@ -1,226 +1,262 @@
     /** {@inheritDoc} */
     @Override
     protected VectorialPointValuePair doOptimize()
         throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
 
         // arrays shared with the other private methods
         solvedCols  = Math.min(rows, cols);
         diagR       = new double[cols];
         jacNorm     = new double[cols];
         beta        = new double[cols];
         permutation = new int[cols];
         lmDir       = new double[cols];
 
         // local point
         double   delta   = 0;
         double   xNorm   = 0;
         double[] diag    = new double[cols];
         double[] oldX    = new double[cols];
         double[] oldRes  = new double[rows];
         double[] work1   = new double[cols];
         double[] work2   = new double[cols];
         double[] work3   = new double[cols];
 
         // evaluate the function at the starting point and calculate its norm
-        updateResidualsAndCost();
+        updateResidualsAndCost(); // Computes cost = sqrt(sum w_i r_i^2), residuals = target - f(point)
 
         // outer loop
         lmPar = 0;
         boolean firstIteration = true;
+        // The objective value passed to the pair is the residual vector (target - f(point))
+        // This is consistent with computeObjectiveValue implementation.
         VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
         while (true) {
             incrementIterationsCounter();
 
             // compute the Q.R. decomposition of the jacobian matrix
             VectorialPointValuePair previous = current;
-            updateJacobian();
-            qrDecomposition();
+            updateJacobian(); // Computes Jacobian J = -df/dp (or df/dp depending on convention)
+            qrDecomposition(); // Computes Q, R, permutation such that J*P = Q*R
 
             // compute Qt.res
-            qTy(residuals);
+            // residuals contains (target - f(point)) from start of iteration
+            qTy(residuals); // residuals now contains g = Q^T * (target - f(point))
             // now we don't need Q anymore,
             // so let jacobian contain the R matrix with its diagonal elements
             for (int k = 0; k < solvedCols; ++k) {
                 int pk = permutation[k];
                 jacobian[k][pk] = diagR[pk];
             }
 
             if (firstIteration) {
-
                 // scale the point according to the norms of the columns
                 // of the initial jacobian
                 xNorm = 0;
                 for (int k = 0; k < cols; ++k) {
-                    double dk = jacNorm[k];
+                    double dk = jacNorm[k]; // Norm of k-th column of J
                     if (dk == 0) {
                         dk = 1.0;
                     }
                     double xk = dk * point[k];
                     xNorm  += xk * xk;
-                    diag[k] = dk;
+                    diag[k] = dk; // Scaling factor D_kk
                 }
-                xNorm = Math.sqrt(xNorm);
+                xNorm = Math.sqrt(xNorm); // xNorm = || D * x ||
 
                 // initialize the step bound delta
                 delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
-
             }
 
             // check orthogonality between function vector and jacobian columns
+            // Check if J^T * r is close to zero. J^T r = P * R^T * Q^T * r = P * R^T * g
             double maxCosine = 0;
-            if (cost != 0) {
+            if (cost != 0) { // cost = ||r|| = ||target - f(point)||
                 for (int j = 0; j < solvedCols; ++j) {
-                    int    pj = permutation[j];
-                    double s  = jacNorm[pj];
+                    int    pj = permutation[j]; // Index in permuted R
+                    double s  = jacNorm[pj]; // Norm of j-th column of J (permuted)
                     if (s != 0) {
+                        // Calculate (R^T * g)_j = sum_{i=0}^{j} R_{i,j} * g_i
                         double sum = 0;
                         for (int i = 0; i <= j; ++i) {
-                            sum += jacobian[i][pj] * residuals[i];
+                            sum += jacobian[i][pj] * residuals[i]; // R_{i,j} * g_i
                         }
+                        // Check cosine similarity: |(J^T r)_j| / (||col_j|| * ||r||)
                         maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                     }
                 }
             }
             if (maxCosine <= orthoTolerance) {
-                // convergence has been reached
+                // convergence has been reached (gradient is perpendicular to columns, i.e., J^T r is small)
                 return current;
             }
 
             // rescale if necessary
             for (int j = 0; j < cols; ++j) {
-                diag[j] = Math.max(diag[j], jacNorm[j]);
+                diag[j] = Math.max(diag[j], jacNorm[j]); // Update scaling D based on current Jacobian
             }
 
-            // inner loop
+            // inner loop - search for a step p such that F(x+p) < F(x)
             for (double ratio = 0; ratio < 1.0e-4;) {
 
                 // save the state
                 for (int j = 0; j < solvedCols; ++j) {
                     int pj = permutation[j];
                     oldX[pj] = point[pj];
                 }
-                double previousCost = cost;
-                double[] tmpVec = residuals;
-                residuals = oldRes;
-                oldRes    = tmpVec;
+                double previousCost = cost; // ||r_old|| = ||target - f(x_old)||
+                double[] tmpVec = residuals; // residuals holds g = Q^T r_old
+                residuals = oldRes; // residuals becomes scratch space
+                oldRes    = tmpVec; // oldRes holds g = Q^T r_old
 
-                // determine the Levenberg-Marquardt parameter
+                // determine the Levenberg-Marquardt parameter lmPar and step p = lmDir
+                // Solves (R^T R + lmPar D^T D) p_solver = -R^T g
                 determineLMParameter(oldRes, delta, diag, work1, work2, work3);
+                // lmDir now holds p_solver
 
                 // compute the new point and the norm of the evolution direction
                 double lmNorm = 0;
                 for (int j = 0; j < solvedCols; ++j) {
                     int pj = permutation[j];
-                    lmDir[pj] = -lmDir[pj];
-                    point[pj] = oldX[pj] + lmDir[pj];
-                    double s = diag[pj] * lmDir[pj];
+                    // Assume determineLMParameter solved for -R^T g, so lmDir is the step p.
+                    // The negation implies it might have solved for +R^T g. We keep it for now.
+                    lmDir[pj] = -lmDir[pj]; // p_actual = -p_solver
+                    point[pj] = oldX[pj] + lmDir[pj]; // x_new = x_old + p_actual
+                    double s = diag[pj] * lmDir[pj]; // (D * p_actual)_j
                     lmNorm  += s * s;
                 }
-                lmNorm = Math.sqrt(lmNorm);
+                lmNorm = Math.sqrt(lmNorm); // lmNorm = || D * p_actual ||
                 // on the first iteration, adjust the initial step bound.
                 if (firstIteration) {
                     delta = Math.min(delta, lmNorm);
                 }
 
                 // evaluate the function at x + p and calculate its norm
-                updateResidualsAndCost();
+                updateResidualsAndCost(); // Updates cost = ||r_new||, residuals = r_new = target - f(x_new)
+                                        // Also updates objective array to r_new for the checker
                 current = new VectorialPointValuePair(point, objective);
 
-                // compute the scaled actual reduction
+                // compute the scaled actual reduction: (||r_old||^2 - ||r_new||^2) / ||r_old||^2
                 double actRed = -1.0;
-                if (0.1 * cost < previousCost) {
-                    double r = cost / previousCost;
+                if (0.1 * cost < previousCost) { // Ensure previousCost is not too small
+                    double r = cost / previousCost; // ||r_new|| / ||r_old||
                     actRed = 1.0 - r * r;
                 }
 
                 // compute the scaled predicted reduction
                 // and the scaled directional derivative
+                // Compute work1 = R * p_actual
                 for (int j = 0; j < solvedCols; ++j) {
                     int pj = permutation[j];
-                    double dirJ = lmDir[pj];
-                    work1[j] = 0;
+                    double dirJ = lmDir[pj]; // Component j of p_actual (permuted)
+                    work1[j] = 0; // Initialize work1[j] -- THIS IS A BUG, should initialize before inner loop
+                                  // Corrected: inner loop correctly calculates work1[i] = sum_{j>=i} R_{ij} * dirJ
+                    // The following loop computes work1 = R * p_actual where R is upper triangular stored in jacobian
                     for (int i = 0; i <= j; ++i) {
                         work1[i] += jacobian[i][pj] * dirJ;
                     }
                 }
                 double coeff1 = 0;
                 for (int j = 0; j < solvedCols; ++j) {
-                    coeff1 += work1[j] * work1[j];
+                    coeff1 += work1[j] * work1[j]; // coeff1 = || R * p_actual ||^2
                 }
-                double pc2 = previousCost * previousCost;
-                coeff1 = coeff1 / pc2;
-                double coeff2 = lmPar * lmNorm * lmNorm / pc2;
-                double preRed = coeff1 + 2 * coeff2;
+                double pc2 = previousCost * previousCost; // pc2 = ||r_old||^2
+                coeff1 = coeff1 / pc2; // Scaled || R * p_actual ||^2
+                double coeff2 = lmPar * lmNorm * lmNorm / pc2; // Scaled lmPar * || D * p_actual ||^2
+
+                // Predicted reduction: (L(0) - L(p)) / ||r_old||^2 approx (||Jp||^2 + lmPar ||Dp||^2) / ||r_old||^2
+                // Assuming ||Jp|| = ||Rp||
+                // FIX: The original code had coeff1 + 2 * coeff2
+                double preRed = coeff1 + coeff2;
+
+                // Directional derivative: grad(C)^T p / ||r_old||^2 = -(||Jp||^2 + lmPar ||Dp||^2) / ||r_old||^2
                 double dirDer = -(coeff1 + coeff2);
 
                 // ratio of the actual to the predicted reduction
+                // ratio = actRed / preRed = [ (||r_old||^2 - ||r_new||^2) / ||r_old||^2 ] / [ (||Rp||^2 + lmPar ||Dp||^2) / ||r_old||^2 ]
+                // ratio = (||r_old||^2 - ||r_new||^2) / (||Rp||^2 + lmPar ||Dp||^2)
                 ratio = (preRed == 0) ? 0 : (actRed / preRed);
 
                 // update the step bound
                 if (ratio <= 0.25) {
+                    // step was bad, reduce trust region/increase damping
                     double tmp =
                         (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
-                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
+                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) { // Ensure tmp is not too small
                             tmp = 0.1;
                         }
-                        delta = tmp * Math.min(delta, 10.0 * lmNorm);
-                        lmPar /= tmp;
+                        delta = tmp * Math.min(delta, 10.0 * lmNorm); // Decrease delta
+                        lmPar /= tmp; // Increase lmPar
                 } else if ((lmPar == 0) || (ratio >= 0.75)) {
-                    delta = 2 * lmNorm;
-                    lmPar *= 0.5;
+                    // step was good, increase trust region/decrease damping
+                    delta = 2 * lmNorm; // Increase delta (related to step size)
+                    lmPar *= 0.5; // Decrease lmPar
                 }
 
                 // test for successful iteration.
                 if (ratio >= 1.0e-4) {
-                    // successful iteration, update the norm
+                    // successful iteration, update the norm of the variables
                     firstIteration = false;
                     xNorm = 0;
                     for (int k = 0; k < cols; ++k) {
                         double xK = diag[k] * point[k];
                         xNorm    += xK * xK;
                     }
-                    xNorm = Math.sqrt(xNorm);
+                    xNorm = Math.sqrt(xNorm); // || D * x_new ||
 
                     // tests for convergence.
-                    // we use the vectorial convergence checker
+                    // Check if checker is provided or use internal tests.
                 } else {
                     // failed iteration, reset the previous values
-                    cost = previousCost;
+                    cost = previousCost; // Restore cost = ||r_old||
                     for (int j = 0; j < solvedCols; ++j) {
                         int pj = permutation[j];
-                        point[pj] = oldX[pj];
+                        point[pj] = oldX[pj]; // Restore point x_old
                     }
-                    tmpVec    = residuals;
-                    residuals = oldRes;
-                    oldRes    = tmpVec;
+                    tmpVec    = residuals; // Swap residuals/oldRes back
+                    residuals = oldRes;    // residuals holds g = Q^T r_old
+                    oldRes    = tmpVec;    // oldRes is scratch
+                    // Reset current VectorialPointValuePair to previous? No, previous is saved at start of loop.
+                    current = previous;
                 }
+
+                // Check convergence AFTER potentially restoring previous state if iteration failed
                 if (checker==null) {
-                	if (((Math.abs(actRed) <= costRelativeTolerance) &&
-                        (preRed <= costRelativeTolerance) &&
-                        (ratio <= 2.0)) ||
-                       (delta <= parRelativeTolerance * xNorm)) {
-                       return current;
+                    // Default convergence criteria
+                    if (((Math.abs(actRed) <= costRelativeTolerance) && // Relative change in cost is small
+                         (preRed <= costRelativeTolerance) && // Predicted relative change is small
+                         (ratio <= 2.0)) || // Actual change is not much larger than predicted
+                        (delta <= parRelativeTolerance * xNorm)) { // Step size (trust region) is small relative to parameters
+                        return current; // Return current (could be previous if iteration failed)
                     }
                  } else {
                      if (checker.converged(getIterations(), previous, current)) {
                          return current;
                      }
                  }
-                // tests for termination and stringent tolerances
-                // (2.2204e-16 is the machine epsilon for IEEE754)
+
+                // check termination conditions (stagnation or too small tolerances)
                 if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                     throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,
                             costRelativeTolerance);
                 } else if (delta <= 2.2204e-16 * xNorm) {
                     throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,
                             parRelativeTolerance);
                 } else if (maxCosine <= 2.2204e-16)  {
                     throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,
                             orthoTolerance);
                 }
 
+                // If iteration was successful, break inner loop and start next outer iteration
+                // If iteration failed, ratio < 1.0e-4, continue inner loop to try different lmPar/delta
+                if (ratio >= 1.0e-4) {
+                   break; // Go to next outer iteration
                 }
+            } // End inner loop (ratio >= 1.0e-4 breaks or max iterations exceeded implicitly?)
+             // If inner loop finishes without finding a good step (ratio stays < 1.0e-4),
+             // the outer loop continues, potentially recomputing Jacobian etc.
+             // This seems like it could loop indefinitely if determineLMParameter keeps failing.
+             // However, lmPar increases in the inner loop, eventually forcing a small step.
 
-        }
+        } // End outer loop (should be terminated by return or exception)
 
     }
\ No newline at end of file
