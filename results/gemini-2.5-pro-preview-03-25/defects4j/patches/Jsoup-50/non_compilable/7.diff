diff --git a/tmp/cb5dce3f-4e7f-45fe-917a-2a1629b12827_buggy.java b/tmp/0b79d93b-a328-4e82-bc8c-28bb517945c0_fixed.java
index 25ca093..fe99d4e 100644
--- a/tmp/cb5dce3f-4e7f-45fe-917a-2a1629b12827_buggy.java
+++ b/tmp/0b79d93b-a328-4e82-bc8c-28bb517945c0_fixed.java
@@ -1,52 +1,165 @@
-    // todo - this is getting gnarly. needs a rewrite.
+import org.jsoup.nodes.Document;
+import org.jsoup.nodes.Element;
+import org.jsoup.parser.Parser;
+import org.jsoup.helper.Validate;
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
+import java.nio.charset.IllegalCharsetNameException;
+
+// NOTE: This code block assumes the existence of:
+// - DataUtil.defaultCharset (String, e.g., "UTF-8")
+// - DataUtil.UNICODE_BOM (char, '\uFEFF')
+// - DataUtil.getCharsetFromContentType(String) (method)
+// These are typically defined elsewhere in the org.jsoup.helper.DataUtil class.
+
+class FixedDataUtil { // Helper class just to provide context for the static method
+
+    // Assume these are defined elsewhere, e.g., in DataUtil
+    private static final String defaultCharset = "UTF-8";
+    private static final char UNICODE_BOM = '\uFEFF';
+    private static String getCharsetFromContentType(String contentType) {
+        // This is a simplified placeholder implementation based on common patterns.
+        // The actual implementation in Jsoup might be more robust.
+        if (contentType == null) return null;
+        String[] params = contentType.toLowerCase().split(";");
+        for (String param : params) {
+            param = param.trim();
+            if (param.startsWith("charset=")) {
+                String charset = param.substring("charset=".length());
+                // Remove surrounding quotes if present
+                if (charset.length() > 1 && ((charset.startsWith("\"") && charset.endsWith("\"")) || (charset.startsWith("'") && charset.endsWith("'")))) {
+                    charset = charset.substring(1, charset.length() - 1);
+                }
+                return charset.trim();
+            }
+        }
+        return null;
+    }
+
+
+    /**
+     * Parses the input ByteBuffer to a Document.
+     * @param byteData ByteBuffer to parse
+     * @param charsetName Character set of file contents, or null to detect automatically.
+     * @param baseUri The URL where the HTML was retrieved from, to resolve relative links against.
+     * @param parser The parser to use.
+     * @return Document
+     */
     static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {
-        String docData;
+        String docData = null;
         Document doc = null;
+        boolean bomFound = false; // Keep track if BOM determined the charset
 
-        // look for BOM - overrides any other header or input
+        // *** Stage 1: Determine the character set. ***
+        // Handle Byte Order Marks (BOMs) upfront. BOM overrides any specified or detected charset.
+        byteData.mark();
+        byte[] bom = new byte[4];
+        int read = byteData.remaining() >= bom.length ? bom.length : byteData.remaining();
+        byteData.get(bom, 0, read);
+        byteData.reset(); // Reset buffer to original mark for full decode later
 
-        if (charsetName == null) { // determine from meta. safe parse as UTF-8
-            // look for <meta http-equiv="Content-Type" content="text/html;charset=gb2312"> or HTML5 <meta charset="gb2312">
+        if (read >= 3 && bom[0] == (byte) 0xEF && bom[1] == (byte) 0xBB && bom[2] == (byte) 0xBF) {
+            charsetName = "UTF-8"; // UTF-8 BOM
+            byteData.position(byteData.position() + 3); // Consume BOM bytes
+            bomFound = true;
+        } else if (read >= 2 && bom[0] == (byte) 0xFE && bom[1] == (byte) 0xFF) {
+            charsetName = "UTF-16BE"; // UTF-16 Big Endian BOM
+            byteData.position(byteData.position() + 2);
+            bomFound = true;
+        } else if (read >= 2 && bom[0] == (byte) 0xFF && bom[1] == (byte) 0xFE) {
+            if (read >= 4 && bom[2] == (byte) 0x00 && bom[3] == (byte) 0x00) {
+                charsetName = "UTF-32LE"; // UTF-32 Little Endian BOM
+                byteData.position(byteData.position() + 4);
+                bomFound = true;
+            } else {
+                charsetName = "UTF-16LE"; // UTF-16 Little Endian BOM
+                byteData.position(byteData.position() + 2);
+                bomFound = true;
+            }
+        } else if (read >= 4 && bom[0] == (byte) 0x00 && bom[1] == (byte) 0x00 && bom[2] == (byte) 0xFE && bom[3] == (byte) 0xFF) {
+            charsetName = "UTF-32BE"; // UTF-32 Big Endian BOM
+            byteData.position(byteData.position() + 4);
+            bomFound = true;
+        }
+        // If no BOM found, charsetName remains as passed in (can be null), and buffer position is unchanged.
+
+        // *** Stage 2: Decode the data using the determined character set. ***
+        if (charsetName == null) { // If no BOM and no explicit charset provided, auto-detect from meta tag
+            // Decode tentatively using the default charset (UTF-8)
             docData = Charset.forName(defaultCharset).decode(byteData).toString();
+            // Parse the document tentatively to find meta charset tags
             doc = parser.parseInput(docData, baseUri);
             Element meta = doc.select("meta[http-equiv=content-type], meta[charset]").first();
-            if (meta != null) { // if not found, will keep utf-8 as best attempt
             String foundCharset = null;
+
+            if (meta != null) { // Look for charset information
                 if (meta.hasAttr("http-equiv")) {
                     foundCharset = getCharsetFromContentType(meta.attr("content"));
                 }
                 if (foundCharset == null && meta.hasAttr("charset")) {
                     try {
-                        if (Charset.isSupported(meta.attr("charset"))) {
-                            foundCharset = meta.attr("charset");
+                        String metaCharset = meta.attr("charset");
+                        if (Charset.isSupported(metaCharset)) {
+                            foundCharset = metaCharset;
                         }
                     } catch (IllegalCharsetNameException e) {
+                        // ignore invalid charset names specified in meta tag
                         foundCharset = null;
                     }
                 }
+            }
 
-                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode
+            // If a valid different charset is found in the meta tag, re-decode the input.
+            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equalsIgnoreCase(defaultCharset)) {
+                // clean the found charset name
                 foundCharset = foundCharset.trim().replaceAll("[\"']", "");
-                    charsetName = foundCharset;
-                    byteData.rewind();
-                    docData = Charset.forName(foundCharset).decode(byteData).toString();
-                    doc = null;
+                charsetName = foundCharset; // Update the charset name
+                byteData.rewind(); // Rewind the original byte buffer to the start
+                docData = Charset.forName(charsetName).decode(byteData).toString(); // Decode again with the correct charset
+                doc = null; // Discard the tentatively parsed doc; needs re-parsing
+            } else {
+                // No valid meta charset found, or it's the same as the default.
+                // Stick with the default charset decode. The 'doc' variable already holds the parsed document.
+                // Ensure charsetName is set for output settings later.
+                charsetName = defaultCharset;
             }
-            }
-        } else { // specified by content type header (or by user on file load)
+        } else { // BOM found or charset explicitly specified
+            // We have a charset name (from BOM or explicitly passed in)
             Validate.notEmpty(charsetName, "Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML");
-            docData = Charset.forName(charsetName).decode(byteData).toString();
-        }
-        if (docData.length() > 0 && docData.charAt(0) == UNICODE_BOM) {
-            byteData.rewind();
-            docData = Charset.forName(defaultCharset).decode(byteData).toString();
-            docData = docData.substring(1);
-            charsetName = defaultCharset;
-            doc = null;
+            docData = Charset.forName(charsetName).decode(byteData).toString(); // Decode using the known charset
         }
+
+        // *** Stage 3: Parse the decoded data. ***
         if (doc == null) {
+            // Parse the document if:
+            // 1. BOM was found (doc was never parsed).
+            // 2. Charset was specified (doc was never parsed).
+            // 3. Auto-detect found a different meta charset and re-decoded (doc was set to null).
+
+            // Check for and strip the Unicode BOM character (U+FEFF) if it remains after decoding.
+            // Some decoders might not consume it (e.g., standard UTF-8 decoder).
+            if (docData != null && docData.length() > 0 && docData.charAt(0) == UNICODE_BOM) {
+                docData = docData.substring(1);
+            }
+
+            // Avoid NPE if docData somehow became null (should not happen with valid charset decoding)
+            if (docData == null) {
+                docData = "";
+            }
+
             doc = parser.parseInput(docData, baseUri);
+        }
+        // else: doc was already parsed successfully during the auto-detect phase using the default charset.
+
+        // *** Stage 4: Set the document's output charset. ***
+        // Ensure the charsetName used for output settings is the final determined one.
+        if (charsetName == null) {
+             // This should only happen if the input charsetName was null, no BOM was found,
+             // and the meta tag search either failed or confirmed the default charset.
+             charsetName = defaultCharset;
+        }
         doc.outputSettings().charset(charsetName);
-        }
+
         return doc;
     }
+}
\ No newline at end of file
