diff --git a/tmp/66b300e8-502a-4813-9abc-f463801d3a04_buggy.java b/tmp/a7c75fbd-ccad-4386-8da4-d8cc443bf7d6_fixed.java
index db19f52..c0d67c5 100644
--- a/tmp/66b300e8-502a-4813-9abc-f463801d3a04_buggy.java
+++ b/tmp/a7c75fbd-ccad-4386-8da4-d8cc443bf7d6_fixed.java
@@ -1,32 +1,58 @@
     // switching the chartset midstream when a meta http-equiv tag defines the charset.
     static Document parseByteData(ByteBuffer byteData, String charsetName, String baseUri, Parser parser) {
         String docData;
         Document doc = null;
+        final char BOM = '\uFEFF'; // Byte Order Mark
+
         if (charsetName == null) { // determine from meta. safe parse as UTF-8
             // look for <meta http-equiv="Content-Type" content="text/html;charset=gb2312"> or HTML5 <meta charset="gb2312">
             docData = Charset.forName(defaultCharset).decode(byteData).toString();
-            doc = parser.parseInput(docData, baseUri);
+
+            // Check for BOM, remove it before initial parse. Hitting this is potentially unexpected,
+            // as BOMs are usually specific to UTF-16/UTF-32, but better check + strip if present.
+            if (docData.length() > 0 && docData.charAt(0) == BOM) {
+                docData = docData.substring(1);
+            }
+
+            doc = parser.parseInput(docData, baseUri); // Initial parse
             Element meta = doc.select("meta[http-equiv=content-type], meta[charset]").first();
+            String foundCharset = null;
             if (meta != null) { // if not found, will keep utf-8 as best attempt
-                String foundCharset = meta.hasAttr("http-equiv") ? getCharsetFromContentType(meta.attr("content")) : meta.attr("charset");
-                if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equals(defaultCharset)) { // need to re-decode
-                    charsetName = foundCharset;
-                    byteData.rewind();
-                    docData = Charset.forName(foundCharset).decode(byteData).toString();
-                    doc = null;
+                 foundCharset = meta.hasAttr("http-equiv") ? getCharsetFromContentType(meta.attr("content")) : meta.attr("charset");
             }
+
+            if (foundCharset != null && foundCharset.length() != 0 && !foundCharset.equalsIgnoreCase(defaultCharset)) { // need to re-decode. (use equalsIgnoreCase)
+                charsetName = foundCharset; // Update track charset name
+                byteData.rewind(); // Rewind buffer for re-decode
+                docData = Charset.forName(foundCharset).decode(byteData).toString(); // Decode again with found charset
+
+                // Check for BOM again after re-decode
+                if (docData.length() > 0 && docData.charAt(0) == BOM) {
+                    docData = docData.substring(1);
+                }
+                doc = null; // Signal re-parse is needed
+            } else {
+                // No useful charset found in meta, stick with initial parse doc and default charset
+                charsetName = defaultCharset; // Use the default charset name
+                // doc is the initial parse result
             }
         } else { // specified by content type header (or by user on file load)
             Validate.notEmpty(charsetName, "Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML");
             docData = Charset.forName(charsetName).decode(byteData).toString();
+            // Check for BOM, remove it. Relevant for UTF-8 BOMs etc detected after decode.
+            if (docData.length() > 0 && docData.charAt(0) == BOM) {
+                docData = docData.substring(1);
+            }
+            // doc remains null, parse needed
         }
-        if (doc == null) {
-            // there are times where there is a spurious byte-order-mark at the start of the text. Shouldn't be present
-            // in utf-8. If after decoding, there is a BOM, strip it; otherwise will cause the parser to go straight
-            // into head mode
 
+        if (doc == null) { // If parse is needed (because charset specified, or detected different charset requiring re-decode)
+            // docData should now be clean (BOM-stripped if needed) and decoded with the correct charset
             doc = parser.parseInput(docData, baseUri);
+            // charsetName will be non-null here: either the provided one, or the found one, or the default after detection failure/match.
+        }
+
+        // Set the document's output charset to the definitively used one
         doc.outputSettings().charset(charsetName);
-        }
         return doc;
     }
\ No newline at end of file
