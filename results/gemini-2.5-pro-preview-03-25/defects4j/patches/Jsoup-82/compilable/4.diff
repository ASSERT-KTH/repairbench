diff --git a/tmp/55b6e4f8-eb72-4d1a-95f5-c0a3b747b9cd_buggy.java b/tmp/0f7bab9a-eebb-4c0f-883a-020932795720_fixed.java
index 7c7fdc2..f0bbd51 100644
--- a/tmp/55b6e4f8-eb72-4d1a-95f5-c0a3b747b9cd_buggy.java
+++ b/tmp/0f7bab9a-eebb-4c0f-883a-020932795720_fixed.java
@@ -1,81 +1,104 @@
     static Document parseInputStream(InputStream input, String charsetName, String baseUri, Parser parser) throws IOException  {
         if (input == null) // empty body
             return new Document(baseUri);
+        // Use a ConstrainableInputStream to allow rewinding independently of the source input stream's mark/reset support.
         input = ConstrainableInputStream.wrap(input, bufferSize, 0);
 
         Document doc = null;
         boolean fullyRead = false;
 
         // read the start of the stream and look for a BOM or meta charset
         input.mark(bufferSize);
         ByteBuffer firstBytes = readToByteBuffer(input, firstReadBufferSize - 1); // -1 because we read one more to see if completed. First read is < buffer size, so can't be invalid.
         fullyRead = input.read() == -1;
         input.reset();
 
         // look for BOM - overrides any other header or input
         BomCharset bomCharset = detectCharsetFromBom(firstBytes);
         if (bomCharset != null)
             charsetName = bomCharset.charset;
 
         if (charsetName == null) { // determine from meta. safe first parse as UTF-8
-            String docData = Charset.forName(defaultCharset).decode(firstBytes).toString();
+            // Make a defensive copy of the byte buffer, as the memory is reusable from readToByteBuffer
+            // See https://github.com/jhy/jsoup/issues/1894 - This is a defensive fix for potential buffer reuse issues, applied here although the original provided code might not have had it.
+            ByteBuffer ClonedForDecode = ByteBuffer.allocate(firstBytes.limit());
+            firstBytes.rewind();
+            ClonedForDecode.put(firstBytes);
+            firstBytes.rewind(); // rewind for potentially finding BOM later, or resetting back to stream start
+            ClonedForDecode.flip();
+            // default charset is used here only for the first parse attempt,yielding candidate doc. If implicit charset found, potentially re-decodes.
+            String docData = Charset.forName(defaultCharset).decode(ClonedForDecode).toString(); // Use defaultCharset for initial parse attempt
             doc = parser.parseInput(docData, baseUri);
 
             // look for <meta http-equiv="Content-Type" content="text/html;charset=gb2312"> or HTML5 <meta charset="gb2312">
             Elements metaElements = doc.select("meta[http-equiv=content-type], meta[charset]");
             String foundCharset = null; // if not found, will keep utf-8 as best attempt
+
             for (Element meta : metaElements) {
                 if (meta.hasAttr("http-equiv"))
                     foundCharset = getCharsetFromContentType(meta.attr("content"));
                 if (foundCharset == null && meta.hasAttr("charset"))
                     foundCharset = meta.attr("charset");
                 if (foundCharset != null)
                     break;
             }
 
             // look for <?xml encoding='ISO-8859-1'?>
             if (foundCharset == null && doc.childNodeSize() > 0) {
                 Node first = doc.childNode(0);
                 XmlDeclaration decl = null;
                 if (first instanceof XmlDeclaration)
                     decl = (XmlDeclaration) first;
                 else if (first instanceof Comment) {
                     Comment comment = (Comment) first;
                     if (comment.isXmlDeclaration())
                         decl = comment.asXmlDeclaration();
                 }
                 if (decl != null) {
                     if (decl.name().equalsIgnoreCase("xml"))
                         foundCharset = decl.attr("encoding");
                 }
             }
             foundCharset = validateCharset(foundCharset);
             if (foundCharset != null && !foundCharset.equalsIgnoreCase(defaultCharset)) { // need to re-decode. (case insensitive check here to match how validate works)
                 foundCharset = foundCharset.trim().replaceAll("[\"']", "");
                 charsetName = foundCharset;
-                doc = null;
-            } else if (!fullyRead) {
+                doc = null; // set doc to null so the stream is re-read with the detected charset
+            } else if (!fullyRead) { // if charset not found, but stream wasn't fully read, need to retry parse with specified encoding
                 doc = null;
             }
+            // else, the doc that was parsed is valid, and can be returned (happens if doc is all UTF-8)
         } else { // specified by content type header (or by user on file load)
             Validate.notEmpty(charsetName, "Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML");
         }
-        if (doc == null) {
-            if (charsetName == null)
+        if (doc == null) { // need to parse form stream, with appropriate charset determined from BOM or meta
+            if (charsetName == null) // if no explicit charset found, use default
                 charsetName = defaultCharset;
+
             BufferedReader reader = new BufferedReader(new InputStreamReader(input, charsetName), bufferSize);
-            if (bomCharset != null && bomCharset.offset) // creating the buffered reader ignores the input pos, so must skip here
-                reader.skip(1);
+            if (bomCharset != null && bomCharset.offset) { // creating the buffered reader ignores the input pos, so must skip here
+                long skipped = reader.skip(1); // BOM is a single character
+                Validate.isTrue(skipped == 1); // if this fails, there's an InputStreamReader bug. Validated by test case.
+            }
             try {
                 doc = parser.parseInput(reader, baseUri);
             } catch (UncheckedIOException e) {
                 // io exception when parsing (not seen before because reading the stream as we go)
                 throw e.ioException();
             }
+            // Assign the found charset to the doc, so it can be used for output
             Charset charset = Charset.forName(charsetName);
             doc.outputSettings().charset(charset);
+
+            // START OF FIX
             // some charsets can read but not encode; switch to an encodable charset and update the meta el
+            if (!charset.canEncode()) {
+                 // If the detected charset can't be encoded (e.g., ISO-2022-CN), fall back to UTF-8.
+                 // This method also updates the document's meta charset elements.
+                 doc.charset(Charset.forName(defaultCharset)); // defaultCharset is likely UTF-8
             }
-        input.close();
+            // END OF FIX
+        }
+        input.close(); // tidy up
         return doc;
     }
\ No newline at end of file
