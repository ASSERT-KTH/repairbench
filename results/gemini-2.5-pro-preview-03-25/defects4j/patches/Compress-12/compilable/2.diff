diff --git a/tmp/ae8a1c64-3be1-46a7-a9ee-e22064065698_buggy.java b/tmp/4804cd0f-4f39-4efe-b59f-ab000f7dcfa4_fixed.java
index b5a206b..ad0556f 100644
--- a/tmp/ae8a1c64-3be1-46a7-a9ee-e22064065698_buggy.java
+++ b/tmp/4804cd0f-4f39-4efe-b59f-ab000f7dcfa4_fixed.java
@@ -1,80 +1,93 @@
     /**
      * Get the next entry in this tar archive. This will skip
      * over any remaining data in the current entry, if there
      * is one, and place the input stream at the header of the
      * next entry, and read the header and instantiate a new
      * TarEntry from the header bytes and return that entry.
      * If there are no more entries in the archive, null will
      * be returned to indicate that the end of the archive has
      * been reached.
      *
      * @return The next TarEntry in the archive, or null.
      * @throws IOException on error
      */
     public TarArchiveEntry getNextTarEntry() throws IOException {
         if (hasHitEOF) {
             return null;
         }
 
         if (currEntry != null) {
+            /* Skip will only work if the stream is underlyingly seekable */
             long numToSkip = entrySize - entryOffset;
 
-            while (numToSkip > 0) {
-                long skipped = skip(numToSkip);
-                if (skipped <= 0) {
-                    throw new RuntimeException("failed to skip current tar entry");
-                }
-                numToSkip -= skipped;
+            //         System.out.println("TarAE.skip(" + numToSkip + ") byte: '" + (char)readByte() + "'");
+
+
+            // WORKAROUND:
+            //   Apparently BufferedInputStream skips fail for > 2GB on some platforms
+            //   So, we use the read() method
+            // OTherwise, just skip the rest of the data.
+            //
+            if (numToSkip > 0) {
+                skip(numToSkip);
             }
 
             readBuf = null;
         }
 
         byte[] headerBuf = getRecord();
 
         if (hasHitEOF) {
             currEntry = null;
             return null;
         }
 
+        try {
             currEntry = new TarArchiveEntry(headerBuf);
+        } catch (IllegalArgumentException e) {
+            IOException ioe = new IOException("Failed to parse tar entry: " + e.getMessage());
+            ioe.initCause(e);
+            throw ioe;
+        }
         entryOffset = 0;
+        // COMPRESS-151 - update entry size dynamically, getSize() may change over the course of this method
         entrySize = currEntry.getSize();
 
         if (currEntry.isGNULongNameEntry()) {
             // read in the name
             StringBuffer longName = new StringBuffer();
             byte[] buf = new byte[SMALL_BUFFER_SIZE];
             int length = 0;
             while ((length = read(buf)) >= 0) {
                 longName.append(new String(buf, 0, length));
             }
             getNextEntry();
             if (currEntry == null) {
                 // Bugzilla: 40334
                 // Malformed tar file - long entry name not followed by entry
                 return null;
             }
-            // remove trailing null terminator
-            if (longName.length() > 0
+            // remove trailing null terminator(s)
+            while (longName.length() > 0
                    && longName.charAt(longName.length() - 1) == 0) {
                 longName.deleteCharAt(longName.length() - 1);
             }
             currEntry.setName(longName.toString());
         }
 
         if (currEntry.isPaxHeader()){ // Process Pax headers
             paxHeaders();
         }
 
         if (currEntry.isGNUSparse()){ // Process sparse files
             readGNUSparse();
         }
 
         // If the size of the next element in the archive has changed
         // due to a new size being reported in the posix header
         // information, we update entrySize here so that it contains
         // the correct value.
+        // COMPRESS-151
         entrySize = currEntry.getSize();
         return currEntry;
     }
\ No newline at end of file
